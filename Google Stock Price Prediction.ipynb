{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6b4aa7b",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network\n",
    "\n",
    "### Part 1: Data Preprocessing\n",
    "\n",
    "**Importing the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fd533e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3c5bca",
   "metadata": {},
   "source": [
    "**Importing the training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3ae84e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-03-2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>73,80,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-04-2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>57,49,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-05-2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>65,90,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-06-2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>54,05,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-09-2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>1,16,88,800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Open    High     Low   Close       Volume\n",
       "0  01-03-2012  325.25  332.83  324.97  663.59    73,80,500\n",
       "1  01-04-2012  331.27  333.87  329.08  666.45    57,49,400\n",
       "2  01-05-2012  329.83  330.75  326.89  657.21    65,90,300\n",
       "3  01-06-2012  328.34  328.77  323.68  648.24    54,05,900\n",
       "4  01-09-2012  322.04  322.29  309.46  620.76  1,16,88,800"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = pd.read_csv('Google_Stock_Price_Train.csv')\n",
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d1b775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[325.25],\n",
       "       [331.27],\n",
       "       [329.83],\n",
       "       ...,\n",
       "       [793.7 ],\n",
       "       [783.33],\n",
       "       [782.75]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = dataset_train.iloc[:,1:2].values\n",
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffc9f25",
   "metadata": {},
   "source": [
    "**Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a88e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0880dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cfdc4f",
   "metadata": {},
   "source": [
    "**Creating a data structure with 60 timesteps and 1 output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3885d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, 1258):\n",
    "    X_train.append(training_set_scaled[i-60:i,0])\n",
    "    y_train.append(training_set_scaled[i,0])\n",
    "    \n",
    "X_train,y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6a1c75",
   "metadata": {},
   "source": [
    "**Reshaping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bbdb73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c02be7",
   "metadata": {},
   "source": [
    "### Part:2 Building and training the RNN\n",
    "\n",
    "**Importing the keras libraries and packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "663df2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64cc8a5",
   "metadata": {},
   "source": [
    "**Installing the RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bdbd044",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d23ef20",
   "metadata": {},
   "source": [
    "**Adding the first LSTM layer and some Dropout regularisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0e15125",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50, return_sequences=True,input_shape=(X_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40249ec9",
   "metadata": {},
   "source": [
    "**Adding the second LSTM layer and some Dropout regularisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ba11b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50, return_sequences=True,))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6388c",
   "metadata": {},
   "source": [
    "**Adding the third LSTM layer and some Dropout regularisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9d59db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50, return_sequences=True,))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b03ed14",
   "metadata": {},
   "source": [
    "**Adding the fourth LSTM layer and some Dropout regularisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d8173c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50, return_sequences=True,))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c7d3f1",
   "metadata": {},
   "source": [
    "**Adding the output layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aa9af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55ef169",
   "metadata": {},
   "source": [
    "**Compilling the RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4fe229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de702d",
   "metadata": {},
   "source": [
    "**Fitting the RNN to the Training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c067dd62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 15s 37ms/step - loss: 0.1259\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0865\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0827\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0820\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0804\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0801\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.0797\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.0790\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.0785\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.0776\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0782\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0779\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.0769\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0768\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0764\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0767\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0763\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.0769\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.0763\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0764\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.0758\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.0758\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0757\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0757\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0759\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0757\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0757\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.0754\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.0756\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0758\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.0756\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.0753\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0758\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0759\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.0753\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.0752\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0754\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0752\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.0750\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.0754\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.0754\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0752\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0754\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.0756\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.0754\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.0751\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.0752\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.0756\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0757\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0755\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0757\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.0751\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.0750\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.0751\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0751\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.0749\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0750\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0749\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.0755\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.0751\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0754\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.0751\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.0750\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0749\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0749\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0750\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0751\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0750\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0749\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0748\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0753\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0748\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.0748\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.0749\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0749\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0748\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0750\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.0750\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0748\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.0749\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.0748\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.0750\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.0748\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.0748\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0749\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0748\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0751\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0749\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.0750\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0748\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.0749\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0748\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0748\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0747\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0748\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0750\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0748\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.0748\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.0747\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 134.18895173072815 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "regressor.fit(X_train,y_train,epochs=100,batch_size=32)\n",
    "end_time = time.time()\n",
    "print(f\"Training took {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba585b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu takes 118.09218287467957 seconds\n",
    "# 233.2605926990509 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07ad81c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 4s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = regressor.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e137235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.49962008],\n",
       "        [0.49525914],\n",
       "        [0.4971602 ],\n",
       "        ...,\n",
       "        [0.48702008],\n",
       "        [0.487105  ],\n",
       "        [0.4871907 ]],\n",
       "\n",
       "       [[0.49965182],\n",
       "        [0.49528664],\n",
       "        [0.4971813 ],\n",
       "        ...,\n",
       "        [0.4871049 ],\n",
       "        [0.48719054],\n",
       "        [0.48727414]],\n",
       "\n",
       "       [[0.49964422],\n",
       "        [0.49527246],\n",
       "        [0.49713874],\n",
       "        ...,\n",
       "        [0.48719043],\n",
       "        [0.48727405],\n",
       "        [0.4873465 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.50198334],\n",
       "        [0.49950415],\n",
       "        [0.5039209 ],\n",
       "        ...,\n",
       "        [0.50807214],\n",
       "        [0.5080897 ],\n",
       "        [0.5080973 ]],\n",
       "\n",
       "       [[0.50199264],\n",
       "        [0.4995265 ],\n",
       "        [0.50394636],\n",
       "        ...,\n",
       "        [0.5080898 ],\n",
       "        [0.5080973 ],\n",
       "        [0.5081105 ]],\n",
       "\n",
       "       [[0.50200975],\n",
       "        [0.49954236],\n",
       "        [0.5039644 ],\n",
       "        ...,\n",
       "        [0.50809735],\n",
       "        [0.5081105 ],\n",
       "        [0.5080913 ]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1d4bb2",
   "metadata": {},
   "source": [
    "### Evaluating the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b538b9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. None expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[1;32m----> 3\u001b[0m rmse \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      4\u001b[0m rmse\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\metrics\\_regression.py:565\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    516\u001b[0m \n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;124;03m0.825...\u001b[39;00m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    563\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, sample_weight, multioutput)\n\u001b[0;32m    564\u001b[0m _, y_true, y_pred, sample_weight, multioutput \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 565\u001b[0m     \u001b[43m_check_reg_targets_with_floating_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m )\n\u001b[0;32m    569\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    570\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m _average((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\metrics\\_regression.py:198\u001b[0m, in \u001b[0;36m_check_reg_targets_with_floating_dtype\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Ensures that y_true, y_pred, and sample_weight correspond to the same\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03mregression task.\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m dtype_name \u001b[38;5;241m=\u001b[39m _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m--> 198\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m# _check_reg_targets does not accept sample_weight as input.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# Convert sample_weight's data type separately to match dtype_name.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\metrics\\_regression.py:106\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[0;32m    104\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    105\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m--> 106\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    109\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mreshape(y_true, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\utils\\validation.py:1101\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1096\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1097\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1098\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1099\u001b[0m     )\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m-> 1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[0;32m   1107\u001b[0m     _assert_all_finite(\n\u001b[0;32m   1108\u001b[0m         array,\n\u001b[0;32m   1109\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m   1110\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m   1111\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mensure_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1112\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. None expected <= 2."
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = math.sqrt(mean_squared_error(y_train,pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc34931",
   "metadata": {},
   "source": [
    "### Part 3: Making the predictions and visualising the results\n",
    "\n",
    "**Getting the real stock price of 2017**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78479699",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv('Google_Stock_Price_Test.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0685d4f",
   "metadata": {},
   "source": [
    "**Getting the Predicted stock price of 2017**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5136d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']),axis=0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(60,80):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6788fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f4b75f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d484a94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977fb483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gputest)",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
